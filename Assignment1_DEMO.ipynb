{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "abba7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e07fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('/Users/ruyuliu/Desktop/DeepLearningSELF/PYTORCH_NOTEBOOKS/Assignment1/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b50629",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = ['Pregnancies', 'Glucose', 'BloodPressure', \n",
    "             'SkinThickness', 'Insulin','BMI', \n",
    "             'DiabetesPedigreeFunction', 'Age']\n",
    "y_col = ['Outcome']  # this column contains the labels\n",
    "\n",
    "# Convert continuous variables to a tensor\n",
    "conts = np.stack([diabetes[col].values for col in cont_cols], 1)\n",
    "conts = torch.tensor(conts, dtype=torch.float)\n",
    "\n",
    "# Convert labels to a tensor\n",
    "y = torch.tensor(diabetes[y_col].values).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_cont,out_sz,layers,p=0.5):\n",
    "        \n",
    "        # normalize continuous data that falls in the same magnitude\n",
    "        super().__init__()\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_in = n_cont\n",
    "        \n",
    "        # set up layers, layer = how many layers you want\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "            \n",
    "        # the last layer with output size    \n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "        \n",
    "        # We'll combine the list of layers with torch.nn.Sequential()\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cont):\n",
    "        \n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x_cont = self.layers(x_cont)\n",
    "        \n",
    "        return x_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc2a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(33)\n",
    "model = TabularModel(conts.shape[1], 2, [256],0.4) \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee849d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 768\n",
    "test_size = int(batch_size*0.2)\n",
    "\n",
    "\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe69cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 1500\n",
    "losses = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 40, 60, 80], gamma=0.5, last_epoch=-1)\n",
    "\n",
    "lr_list_1 = []\n",
    "for epoch in range(100):\n",
    "    scheduler.step()\n",
    "    lr_list_1.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "plt.plot(range(100), lr_list_1, color='y', label='lr')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(con_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%50 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5dca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "with torch.no_grad():\n",
    "    y_val = model(con_test)\n",
    "    loss = criterion(y_val, y_test)\n",
    "print(f'CE Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1372bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 153\n",
    "y_valuation = []\n",
    "correct = 0\n",
    "print(f'{\"MODEL OUTPUT\":26} ARGMAX  Y_TEST')\n",
    "for i in range(rows):\n",
    "    print(f'{str(y_val[i]):26} {y_val[i].argmax():^7}{y_test[i]:^7}')\n",
    "    y_valuation.append(y_val[i].argmax().item())\n",
    "    if y_val[i].argmax().item() == y_test[i]:\n",
    "        correct += 1\n",
    "print(f'\\n{correct} out of {rows} = {100*correct/rows:.2f}% correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ca700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test.numpy(), y_valuation))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test.numpy(), y_valuation))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test.numpy(), y_valuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe38af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a37ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e8d398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a7bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0685a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a380b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02514b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3755be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10,7))\n",
    "fig.tight_layout()\n",
    "\n",
    "plots = [(0,1),(0,2),(0,3),(0,4),(0,5),(0,6),(1,2),(1,3),(1,4),(1,5),(1,6),(2,3),(2,4),(2,5),(2,6),(3,4)]\n",
    "colors = ['b', 'r']\n",
    "labels = ['no','yes']\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    for j in range(2):\n",
    "        x = diabetes.columns[plots[i][0]]\n",
    "        y = diabetes.columns[plots[i][1]]\n",
    "        ax.scatter(diabetes[diabetes['Outcome']==j][x], diabetes[diabetes['Outcome']==j][y], color=colors[j])\n",
    "        ax.set(xlabel=x, ylabel=y)\n",
    "\n",
    "fig.legend(labels=labels, loc=3, bbox_to_anchor=(1.0,0.85))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
